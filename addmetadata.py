import tensorflow as tf
from tflite_support.metadata_writers import object_detector
from tflite_support.metadata_writers import writer_utils

# Define the path to the model and label file.
model_path = "best_cpu-fp16.tflite" # input your model in tflite format
label_file_path = "label.txt"      # input your label

# Create the metadata writer.
writer = object_detector.MetadataWriter.create_for_inference(
    tf.lite.model_path(model_path),
    [127.5],
    [127.5],
    [label_file_path])

# Verify the metadata generated by the metadata writer.
print(writer.get_metadata_json())

# Populate the metadata into the model.
writer_utils.save_file(writer.populate(), "hasil_coba.tflite") # name result model

# Display the metadata in the model.
displayer = metadata.MetadataDisplayer.with_model_file("hasil_coba.tflite") # add metadata to model
print("Metadata populated:")
print(displayer.get_metadata_json())

print("Associated file(s) populated:")
for file_name in displayer.get_packed_associated_file_list():
  print("file name: ", file_name)
  print("file content:")
  print(displayer.get_associated_file_buffer(file_name))